{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers={'User-Agent':'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:66.0) Gecko/20100101 Firefox/66.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resturants urls\n",
    "links=pd.read_csv(\"links.csv\")\n",
    "links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"http://swiggy.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_rest=links['links'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = url + links['links'].astype(str)\n",
    "urls=urls.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pareser to get data of each restaurants\n",
    "def parse(url):\n",
    "    try:\n",
    "        response=requests.get(url,headers=headers)\n",
    "        time.sleep(5)\n",
    "        if response.status_code==200:\n",
    "            content=response.content\n",
    "            soup=BeautifulSoup(content,\"html.parser\")\n",
    "            data=json.loads(soup.find('script', type='application/ld+json').text)\n",
    "            nam=data['name']\n",
    "            reg=data['address']['addressRegion']\n",
    "            lon=data['geo']['longitude']\n",
    "            lat=data['geo']['latitude']\n",
    "            pri=data['priceRange']\n",
    "            rat=data['aggregateRating']['ratingValue']\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "    return nam,lon,lat,pri,reg,rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiprocessing to speed up scraping\n",
    "with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    future_results = {executor.submit(parse, url): url for url in urls}\n",
    "    results = []\n",
    "    for future in concurrent.futures.as_completed(future_results):\n",
    "        results.append(future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(list(results),columns = [\"Restaurant Name\",\"Longitude\",\"Latitude\",\"Price\", \"Region\",\"Rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing price for two\n",
    "price=df[\"Price\"]\n",
    "price_for_two=[]\n",
    "for i in range(len(price)):\n",
    "    en=price[i].encode('ascii','ignore')\n",
    "    en=en.decode('utf-8') \n",
    "    pr=re.findall(r'\\d+',en)\n",
    "    for i in pr:  \n",
    "        price_for_two.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Price For Two\"]=price_for_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('Price',axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Data\n",
    "df.to_csv(\"scrape_data.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
